{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import yaml\n",
    "# import wandb\n",
    "\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "from training.create_dataset import *\n",
    "from training.create_network import *\n",
    "from training.utils import create_task_flags, TaskMetric, compute_loss, eval\n",
    "from utils import torch_save, get_data_loaders, initialize_wandb\n",
    "\n",
    "# Login to wandb\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for training\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "template = env.get_template('config/mtl.yaml.j2')\n",
    "rendered_yaml = template.render()\n",
    "config = yaml.safe_load(rendered_yaml)\n",
    "\n",
    "# Create logging folder to store training weights and losses\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "model_classes = {\n",
    "  \"split\": MTLDeepLabv3,\n",
    "  \"mtan\": MTANDeepLabv3,\n",
    "  # \"dinov2\": MTLDinoVisionTransformer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config[\"training_params\"][\"seed\"])\n",
    "np.random.seed(config[\"training_params\"][\"seed\"])\n",
    "random.seed(config[\"training_params\"][\"seed\"])\n",
    "\n",
    "# device = torch.device(f\"cuda:{config[\"training_params\"]['gpu']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_data_loaders(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juangarcia/Dropbox/Course/Year 2/Semester 1/Semester Project/repositories/simomm/models/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/Users/juangarcia/Dropbox/Course/Year 2/Semester 1/Semester Project/repositories/simomm/models/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/Users/juangarcia/Dropbox/Course/Year 2/Semester 1/Semester Project/repositories/simomm/models/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "/Users/juangarcia/Dropbox/Course/Year 2/Semester 1/Semester Project/repositories/simomm/models/dinov2/losses/cross_entropy_loss.py:220: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from models.dinov2.mtl.multitasker import MTLDinoV2\n",
    "\n",
    "model = MTLDinoV2(\n",
    "  arch_name=\"vit_small\",\n",
    "  head_tasks={\n",
    "    \"seg\": {\n",
    "      \"num_classes\": 13,\n",
    "    },\n",
    "    \"depth\": {\n",
    "      \"num_classes\": 1,\n",
    "      \"min_depth\": 0.001,\n",
    "      \"max_depth\": 10.0,\n",
    "    },\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['backbone.cls_token', 'backbone.pos_embed', 'backbone.mask_token', 'backbone.patch_embed.proj.weight', 'backbone.patch_embed.proj.bias', 'backbone.blocks.0.norm1.weight', 'backbone.blocks.0.norm1.bias', 'backbone.blocks.0.attn.qkv.weight', 'backbone.blocks.0.attn.qkv.bias', 'backbone.blocks.0.attn.proj.weight', 'backbone.blocks.0.attn.proj.bias', 'backbone.blocks.0.ls1.gamma', 'backbone.blocks.0.norm2.weight', 'backbone.blocks.0.norm2.bias', 'backbone.blocks.0.mlp.fc1.weight', 'backbone.blocks.0.mlp.fc1.bias', 'backbone.blocks.0.mlp.fc2.weight', 'backbone.blocks.0.mlp.fc2.bias', 'backbone.blocks.0.ls2.gamma', 'backbone.blocks.1.norm1.weight', 'backbone.blocks.1.norm1.bias', 'backbone.blocks.1.attn.qkv.weight', 'backbone.blocks.1.attn.qkv.bias', 'backbone.blocks.1.attn.proj.weight', 'backbone.blocks.1.attn.proj.bias', 'backbone.blocks.1.ls1.gamma', 'backbone.blocks.1.norm2.weight', 'backbone.blocks.1.norm2.bias', 'backbone.blocks.1.mlp.fc1.weight', 'backbone.blocks.1.mlp.fc1.bias', 'backbone.blocks.1.mlp.fc2.weight', 'backbone.blocks.1.mlp.fc2.bias', 'backbone.blocks.1.ls2.gamma', 'backbone.blocks.2.norm1.weight', 'backbone.blocks.2.norm1.bias', 'backbone.blocks.2.attn.qkv.weight', 'backbone.blocks.2.attn.qkv.bias', 'backbone.blocks.2.attn.proj.weight', 'backbone.blocks.2.attn.proj.bias', 'backbone.blocks.2.ls1.gamma', 'backbone.blocks.2.norm2.weight', 'backbone.blocks.2.norm2.bias', 'backbone.blocks.2.mlp.fc1.weight', 'backbone.blocks.2.mlp.fc1.bias', 'backbone.blocks.2.mlp.fc2.weight', 'backbone.blocks.2.mlp.fc2.bias', 'backbone.blocks.2.ls2.gamma', 'backbone.blocks.3.norm1.weight', 'backbone.blocks.3.norm1.bias', 'backbone.blocks.3.attn.qkv.weight', 'backbone.blocks.3.attn.qkv.bias', 'backbone.blocks.3.attn.proj.weight', 'backbone.blocks.3.attn.proj.bias', 'backbone.blocks.3.ls1.gamma', 'backbone.blocks.3.norm2.weight', 'backbone.blocks.3.norm2.bias', 'backbone.blocks.3.mlp.fc1.weight', 'backbone.blocks.3.mlp.fc1.bias', 'backbone.blocks.3.mlp.fc2.weight', 'backbone.blocks.3.mlp.fc2.bias', 'backbone.blocks.3.ls2.gamma', 'backbone.blocks.4.norm1.weight', 'backbone.blocks.4.norm1.bias', 'backbone.blocks.4.attn.qkv.weight', 'backbone.blocks.4.attn.qkv.bias', 'backbone.blocks.4.attn.proj.weight', 'backbone.blocks.4.attn.proj.bias', 'backbone.blocks.4.ls1.gamma', 'backbone.blocks.4.norm2.weight', 'backbone.blocks.4.norm2.bias', 'backbone.blocks.4.mlp.fc1.weight', 'backbone.blocks.4.mlp.fc1.bias', 'backbone.blocks.4.mlp.fc2.weight', 'backbone.blocks.4.mlp.fc2.bias', 'backbone.blocks.4.ls2.gamma', 'backbone.blocks.5.norm1.weight', 'backbone.blocks.5.norm1.bias', 'backbone.blocks.5.attn.qkv.weight', 'backbone.blocks.5.attn.qkv.bias', 'backbone.blocks.5.attn.proj.weight', 'backbone.blocks.5.attn.proj.bias', 'backbone.blocks.5.ls1.gamma', 'backbone.blocks.5.norm2.weight', 'backbone.blocks.5.norm2.bias', 'backbone.blocks.5.mlp.fc1.weight', 'backbone.blocks.5.mlp.fc1.bias', 'backbone.blocks.5.mlp.fc2.weight', 'backbone.blocks.5.mlp.fc2.bias', 'backbone.blocks.5.ls2.gamma', 'backbone.blocks.6.norm1.weight', 'backbone.blocks.6.norm1.bias', 'backbone.blocks.6.attn.qkv.weight', 'backbone.blocks.6.attn.qkv.bias', 'backbone.blocks.6.attn.proj.weight', 'backbone.blocks.6.attn.proj.bias', 'backbone.blocks.6.ls1.gamma', 'backbone.blocks.6.norm2.weight', 'backbone.blocks.6.norm2.bias', 'backbone.blocks.6.mlp.fc1.weight', 'backbone.blocks.6.mlp.fc1.bias', 'backbone.blocks.6.mlp.fc2.weight', 'backbone.blocks.6.mlp.fc2.bias', 'backbone.blocks.6.ls2.gamma', 'backbone.blocks.7.norm1.weight', 'backbone.blocks.7.norm1.bias', 'backbone.blocks.7.attn.qkv.weight', 'backbone.blocks.7.attn.qkv.bias', 'backbone.blocks.7.attn.proj.weight', 'backbone.blocks.7.attn.proj.bias', 'backbone.blocks.7.ls1.gamma', 'backbone.blocks.7.norm2.weight', 'backbone.blocks.7.norm2.bias', 'backbone.blocks.7.mlp.fc1.weight', 'backbone.blocks.7.mlp.fc1.bias', 'backbone.blocks.7.mlp.fc2.weight', 'backbone.blocks.7.mlp.fc2.bias', 'backbone.blocks.7.ls2.gamma', 'backbone.blocks.8.norm1.weight', 'backbone.blocks.8.norm1.bias', 'backbone.blocks.8.attn.qkv.weight', 'backbone.blocks.8.attn.qkv.bias', 'backbone.blocks.8.attn.proj.weight', 'backbone.blocks.8.attn.proj.bias', 'backbone.blocks.8.ls1.gamma', 'backbone.blocks.8.norm2.weight', 'backbone.blocks.8.norm2.bias', 'backbone.blocks.8.mlp.fc1.weight', 'backbone.blocks.8.mlp.fc1.bias', 'backbone.blocks.8.mlp.fc2.weight', 'backbone.blocks.8.mlp.fc2.bias', 'backbone.blocks.8.ls2.gamma', 'backbone.blocks.9.norm1.weight', 'backbone.blocks.9.norm1.bias', 'backbone.blocks.9.attn.qkv.weight', 'backbone.blocks.9.attn.qkv.bias', 'backbone.blocks.9.attn.proj.weight', 'backbone.blocks.9.attn.proj.bias', 'backbone.blocks.9.ls1.gamma', 'backbone.blocks.9.norm2.weight', 'backbone.blocks.9.norm2.bias', 'backbone.blocks.9.mlp.fc1.weight', 'backbone.blocks.9.mlp.fc1.bias', 'backbone.blocks.9.mlp.fc2.weight', 'backbone.blocks.9.mlp.fc2.bias', 'backbone.blocks.9.ls2.gamma', 'backbone.blocks.10.norm1.weight', 'backbone.blocks.10.norm1.bias', 'backbone.blocks.10.attn.qkv.weight', 'backbone.blocks.10.attn.qkv.bias', 'backbone.blocks.10.attn.proj.weight', 'backbone.blocks.10.attn.proj.bias', 'backbone.blocks.10.ls1.gamma', 'backbone.blocks.10.norm2.weight', 'backbone.blocks.10.norm2.bias', 'backbone.blocks.10.mlp.fc1.weight', 'backbone.blocks.10.mlp.fc1.bias', 'backbone.blocks.10.mlp.fc2.weight', 'backbone.blocks.10.mlp.fc2.bias', 'backbone.blocks.10.ls2.gamma', 'backbone.blocks.11.norm1.weight', 'backbone.blocks.11.norm1.bias', 'backbone.blocks.11.attn.qkv.weight', 'backbone.blocks.11.attn.qkv.bias', 'backbone.blocks.11.attn.proj.weight', 'backbone.blocks.11.attn.proj.bias', 'backbone.blocks.11.ls1.gamma', 'backbone.blocks.11.norm2.weight', 'backbone.blocks.11.norm2.bias', 'backbone.blocks.11.mlp.fc1.weight', 'backbone.blocks.11.mlp.fc1.bias', 'backbone.blocks.11.mlp.fc2.weight', 'backbone.blocks.11.mlp.fc2.bias', 'backbone.blocks.11.ls2.gamma', 'backbone.norm.weight', 'backbone.norm.bias', 'decoders.seg.conv_seg.weight', 'decoders.seg.conv_seg.bias', 'decoders.seg.bn.weight', 'decoders.seg.bn.bias', 'decoders.seg.bn.running_mean', 'decoders.seg.bn.running_var', 'decoders.seg.bn.num_batches_tracked', 'decoders.depth.conv_depth.weight', 'decoders.depth.conv_depth.bias'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "image = images[0].detach().to(device)\n",
    "seg = images[1][\"seg\"].detach().to(device)\n",
    "depth = images[1][\"depth\"].detach().to(device)\n",
    "\n",
    "train_target = {\n",
    "  \"seg\": seg,\n",
    "  \"depth\": depth,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(image, None, img_gt=train_target, return_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seg': {'loss_seg': tensor(2.4415, grad_fn=<MulBackward0>),\n",
       "  'pred': tensor([[[[ 0.0494,  0.6911,  0.6620,  ...,  0.0753, -0.0788,  0.1555],\n",
       "            [-0.1478,  0.0450,  0.8975,  ..., -0.3039, -0.4546, -0.5659],\n",
       "            [ 0.1246,  0.7141,  0.6104,  ...,  0.0733, -0.9006, -0.4133],\n",
       "            ...,\n",
       "            [-0.0076, -0.0243, -0.0885,  ..., -0.3157, -0.4633, -0.1530],\n",
       "            [-0.3220,  0.2048,  0.0620,  ..., -0.7974, -0.5872, -0.1879],\n",
       "            [-0.8817, -0.1928, -0.5731,  ..., -0.1059, -0.3573, -0.1107]],\n",
       "  \n",
       "           [[ 0.5629,  0.5142,  0.4831,  ...,  0.4469,  0.2807,  0.4072],\n",
       "            [ 0.7329,  0.3521,  0.0437,  ...,  0.3831,  0.8722,  1.0950],\n",
       "            [ 0.3497,  0.4082,  0.4747,  ..., -0.0124, -0.1584,  0.4988],\n",
       "            ...,\n",
       "            [ 0.8423, -0.6791,  0.7651,  ...,  0.9749,  0.2351, -0.1885],\n",
       "            [-0.3156, -0.9350,  0.3687,  ..., -0.1062, -0.4299,  0.2010],\n",
       "            [ 0.4749, -0.9616,  0.2249,  ..., -0.7806, -1.0308,  0.3255]],\n",
       "  \n",
       "           [[ 0.7807,  1.1840,  0.9330,  ...,  0.9443,  0.3465, -0.1154],\n",
       "            [-0.0175,  0.2836,  1.9628,  ..., -0.4728,  0.5660,  0.3150],\n",
       "            [ 0.0940,  1.1556,  0.5078,  ...,  0.3832,  0.4257,  0.1399],\n",
       "            ...,\n",
       "            [ 0.1088, -0.0844,  0.1138,  ..., -0.2128, -0.0548,  0.2883],\n",
       "            [ 0.1341, -0.1959,  0.2028,  ..., -0.7316, -0.1446,  0.0828],\n",
       "            [ 0.1293,  0.2591,  0.2008,  ...,  0.0221,  0.0633,  0.8954]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.4090, -0.0045,  0.7978,  ...,  0.7074, -0.0366, -0.0531],\n",
       "            [ 0.2368,  0.1138,  0.5062,  ...,  0.9773, -0.2584, -0.3781],\n",
       "            [ 0.4031, -0.1348,  0.6647,  ..., -0.0858, -0.1768,  0.3668],\n",
       "            ...,\n",
       "            [-0.5271, -0.0334, -0.1642,  ..., -0.6814, -0.2323,  0.6420],\n",
       "            [-0.0176, -0.1095, -0.3222,  ..., -0.4624, -0.2193, -0.1373],\n",
       "            [ 0.2945,  0.0360, -0.1099,  ..., -0.0493, -0.1769, -0.4441]],\n",
       "  \n",
       "           [[ 0.9295,  0.9603,  0.8588,  ..., -0.2384, -0.1751, -0.9364],\n",
       "            [ 0.9321,  0.2818,  0.6634,  ...,  0.9766, -0.1316, -0.6941],\n",
       "            [ 0.2849,  1.0967,  0.0651,  ..., -0.6627,  0.1635,  0.0212],\n",
       "            ...,\n",
       "            [ 0.4823,  0.4891,  0.0948,  ...,  0.1081,  1.0539,  0.4923],\n",
       "            [ 0.6975,  0.6714, -0.0786,  ...,  0.8611,  0.6795, -0.5074],\n",
       "            [ 0.5252,  0.6057, -0.0220,  ...,  0.5351,  0.5102,  0.0526]],\n",
       "  \n",
       "           [[-0.2482, -0.1637, -0.1060,  ...,  0.3634,  0.0410, -0.1461],\n",
       "            [-0.2333, -0.2572,  0.0629,  ...,  0.6110,  0.7799,  0.0042],\n",
       "            [-0.5348, -0.0555,  0.0528,  ...,  0.3444, -0.0614,  0.0678],\n",
       "            ...,\n",
       "            [ 0.2377,  0.2941,  0.0911,  ..., -0.4731, -0.2434,  0.1091],\n",
       "            [ 0.0820,  0.1300,  0.1626,  ..., -0.1857,  0.0818,  0.0097],\n",
       "            [-0.1138,  0.0773,  0.2491,  ..., -0.2459, -0.2010, -0.4317]]],\n",
       "  \n",
       "  \n",
       "          [[[-1.5096, -0.3345, -0.5563,  ...,  0.2125, -0.3459, -0.4595],\n",
       "            [-0.0721, -0.2341, -0.6721,  ...,  0.5669,  0.8131,  0.8831],\n",
       "            [-0.4848,  0.0251, -0.4102,  ..., -0.9880, -0.5009,  0.1004],\n",
       "            ...,\n",
       "            [-0.9303, -0.7212, -0.8696,  ..., -0.4659,  0.5416,  1.3488],\n",
       "            [-0.7036, -0.7605, -0.8654,  ..., -0.2047,  0.1225,  0.2390],\n",
       "            [-0.9267, -1.3749, -1.1042,  ..., -0.5130, -0.0807, -0.7942]],\n",
       "  \n",
       "           [[ 0.8834, -0.0776,  0.3783,  ..., -0.1597,  0.1848, -0.1343],\n",
       "            [ 0.0616,  0.5993, -0.0175,  ...,  0.1032,  0.6550,  0.5804],\n",
       "            [ 0.2746,  0.4278,  0.4932,  ..., -0.0258, -0.2649, -0.0204],\n",
       "            ...,\n",
       "            [ 0.2350, -0.1885, -0.5432,  ...,  0.2987,  0.2274, -0.3116],\n",
       "            [ 0.5788,  0.6317, -0.3611,  ...,  0.2947, -0.4775, -0.4195],\n",
       "            [ 0.6342, -0.1306,  0.3683,  ..., -0.0762,  0.1697,  0.1371]],\n",
       "  \n",
       "           [[ 0.8084,  1.0181,  0.8615,  ...,  1.1187,  1.3252,  0.2545],\n",
       "            [ 0.7623, -0.0979, -0.7080,  ..., -0.3716, -0.5488, -0.1211],\n",
       "            [ 0.5776,  0.1281, -0.4492,  ..., -0.6541, -0.5757, -0.0863],\n",
       "            ...,\n",
       "            [-0.5269, -0.7701, -0.5005,  ...,  0.4849,  0.6667,  0.5331],\n",
       "            [ 0.0792, -0.1688,  0.1047,  ...,  0.8319,  0.4698,  0.3635],\n",
       "            [ 0.4749, -0.0944, -0.1471,  ...,  0.5944,  0.2547,  0.4690]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.4121,  0.4354,  0.3785,  ...,  0.2025,  0.1094, -0.0348],\n",
       "            [-0.0066, -0.5625,  0.5770,  ..., -0.1881, -0.2719, -0.2762],\n",
       "            [-0.4115, -0.4907, -0.3976,  ..., -0.3257,  0.5528, -0.3066],\n",
       "            ...,\n",
       "            [ 0.3650,  0.6137,  1.1738,  ...,  0.1179, -0.4734, -0.1334],\n",
       "            [ 0.7259,  1.4413,  1.0400,  ..., -0.8524, -0.2292,  0.3222],\n",
       "            [ 0.4362,  0.8712,  1.0263,  ..., -0.3932,  0.1489,  0.7377]],\n",
       "  \n",
       "           [[ 0.8088, -0.0660, -0.0644,  ...,  0.1239, -0.3230, -0.7963],\n",
       "            [-0.2167,  0.6328,  0.0601,  ..., -0.5391, -0.5751, -0.7067],\n",
       "            [ 0.0882,  0.5794,  0.0761,  ..., -0.6757, -1.0273, -0.9955],\n",
       "            ...,\n",
       "            [ 0.3266,  0.3149,  0.2963,  ..., -1.5349, -0.2017,  0.5048],\n",
       "            [ 0.4006, -0.2752, -0.4458,  ..., -0.6205,  0.5387, -0.1478],\n",
       "            [ 0.8099,  0.7354,  0.2991,  ..., -0.8022, -0.6085,  0.1731]],\n",
       "  \n",
       "           [[-0.4155, -0.2958, -0.3560,  ..., -0.4887, -1.1824, -0.5504],\n",
       "            [ 0.2131,  0.3756, -0.0226,  ...,  0.1026,  0.4334,  0.3390],\n",
       "            [ 0.0995, -0.0715, -0.0995,  ..., -0.2266,  0.0259, -0.4345],\n",
       "            ...,\n",
       "            [ 0.6507,  0.7540,  1.0273,  ...,  0.7994,  0.4037, -0.0991],\n",
       "            [-0.2285,  0.4209,  1.1028,  ...,  0.9052,  0.1275,  0.2325],\n",
       "            [-0.4681,  0.6793,  1.0702,  ...,  0.5382,  0.4147,  0.3339]]]],\n",
       "         grad_fn=<ConvolutionBackward0>)},\n",
       " 'depth': {'loss_depth': tensor(1.1253, grad_fn=<MulBackward0>),\n",
       "  'loss_grad': tensor(0., grad_fn=<MulBackward0>),\n",
       "  'pred': tensor([[[[40.5926, 40.5926, 40.4511,  ..., 39.7490, 39.6053, 39.6053],\n",
       "            [40.5926, 40.5926, 40.4511,  ..., 39.7490, 39.6053, 39.6053],\n",
       "            [40.5144, 40.5144, 40.3837,  ..., 39.8483, 39.7442, 39.7442],\n",
       "            ...,\n",
       "            [39.7164, 39.7164, 39.8805,  ..., 40.6798, 40.6957, 40.6957],\n",
       "            [39.6379, 39.6379, 39.8120,  ..., 40.7249, 40.7363, 40.7363],\n",
       "            [39.6379, 39.6379, 39.8120,  ..., 40.7249, 40.7363, 40.7363]]],\n",
       "  \n",
       "  \n",
       "          [[[38.6961, 38.6961, 38.5910,  ..., 38.7295, 38.8747, 38.8747],\n",
       "            [38.6961, 38.6961, 38.5910,  ..., 38.7295, 38.8747, 38.8747],\n",
       "            [38.6681, 38.6681, 38.6039,  ..., 38.9266, 39.0236, 39.0236],\n",
       "            ...,\n",
       "            [39.6773, 39.6773, 39.7197,  ..., 39.5765, 39.6371, 39.6371],\n",
       "            [39.6278, 39.6278, 39.6772,  ..., 39.5982, 39.6601, 39.6601],\n",
       "            [39.6278, 39.6278, 39.6772,  ..., 39.5982, 39.6601, 39.6601]]]],\n",
       "         grad_fn=<UnsqueezeBackward0>)}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_metas (list[dict]): List of image info dict where each dict\n",
    "#                 has: 'img_shape', 'scale_factor', 'flip', and may also contain\n",
    "#                 'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
